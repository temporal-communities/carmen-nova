{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    %pip install --quiet polars[numpy,pandas,pyarrow]==1.7.1 requests==2.31.0 lxml==4.9.3 cssselect==1.2.0 plotly kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import polars as pl\n",
    "from typing import Iterator\n",
    "from bisect import bisect_right\n",
    "\n",
    "\n",
    "def etree_elements_to_dicts(elements: Iterator[etree._Element]) -> Iterator[dict]:\n",
    "    for element in elements:\n",
    "        obj = {\n",
    "            \"name\": element.tag,\n",
    "            \"text\": \"\".join(element.itertext()),\n",
    "            \"sourceline\": element.sourceline,\n",
    "            **element.attrib,\n",
    "        }\n",
    "        yield obj\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/temporal-communities/carmen-nova/main/carmen_nova.xml\"\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHBUP5AiImFD"
   },
   "source": [
    "The document is parsed using [lxml](https://lxml.de/).\n",
    "\n",
    "## CSS\n",
    "\n",
    "Use [CSS selector syntax](https://developer.mozilla.org/en-US/docs/Learn/CSS/Building_blocks/Selectors) for querying.\n",
    "\n",
    "For example, to get all `<persName>` and `<author>` elements within `<text>`, use:\n",
    "\n",
    "```\n",
    "text persName, text author\n",
    "```\n",
    "\n",
    "## XPath\n",
    "\n",
    "Use [XPath query syntax](<https://en.wikipedia.org/wiki/XPath#Syntax_and_semantics_(XPath_1.0)>) for querying.\n",
    "\n",
    "For example, to get all `<persName>` and `<author>` elements within `<text>`, use:\n",
    "\n",
    "```\n",
    "//text//persName | //text//author\n",
    "```\n",
    "\n",
    "- [CSS â†’ XPath syntax cheat sheet](https://devhints.io/xpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageBreakLookup:\n",
    "    def __init__(self, dom):\n",
    "        \"\"\"\n",
    "        Initialise the PageBreakLookup with a DOM object.\n",
    "\n",
    "        Args:\n",
    "            dom: The DOM object containing <pb> elements.\n",
    "        \"\"\"\n",
    "        self.page_breaks = [\n",
    "            (int(pb[\"n\"]), pb[\"sourceline\"])\n",
    "            for pb in etree_elements_to_dicts(dom.xpath(\"//pb\"))\n",
    "        ]\n",
    "        self.page_breaks.sort(key=lambda x: x[1])  # Ensure sorted by sourceline\n",
    "\n",
    "    def from_source_line(self, line: int) -> int:\n",
    "        \"\"\"\n",
    "        Get the page number for a given source code line.\n",
    "\n",
    "        Args:\n",
    "            line (int): The source code line number.\n",
    "\n",
    "        Returns:\n",
    "            int: The page number corresponding to the source code line.\n",
    "\n",
    "        If no page break is found before the given line, returns -1.\n",
    "        \"\"\"\n",
    "        idx = bisect_right([pb[1] for pb in self.page_breaks], line) - 1\n",
    "        if idx >= 0:\n",
    "            return self.page_breaks[idx][0]\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run query\n",
    "query_type = \"css\"  # @param [\"css\", \"xpath\"]\n",
    "query = \"text persName, text author\"  # @param [\"text persName, text author\", \"//text//persName | //text//author\"] {allow-input: true}\n",
    "\n",
    "xml_without_namespaces = res.text.replace(\n",
    "    \" xmlns=\", \" xmlnamespace=\", 1\n",
    ")  # Remove namespace to make XPath more convenient\n",
    "dom = etree.XML(xml_without_namespaces.encode())\n",
    "\n",
    "# Initialise page breaks lookup\n",
    "page_breaks = PageBreakLookup(dom)\n",
    "\n",
    "if query_type == \"css\":\n",
    "    data = dom.cssselect(query)\n",
    "elif query_type == \"xpath\":\n",
    "    data = dom.xpath(query, namespaces=dom.nsmap)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown query type: {query_type}\")\n",
    "\n",
    "if len(data) == 0:\n",
    "    raise ValueError(\"No results\")\n",
    "\n",
    "data = etree_elements_to_dicts(data)\n",
    "df = pl.DataFrame(data).with_columns(\n",
    "    text=pl.col(\"text\").str.replace(r\"\\s+\", \" \"),\n",
    "    page=pl.col(\"sourceline\").map_elements(\n",
    "        page_breaks.from_source_line, return_dtype=pl.Int64\n",
    "    ),\n",
    ")\n",
    "df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table: Number of occurrences by reference. Use the mode of the text value.\n",
    "summary = (\n",
    "    df.group_by(\"ref\")\n",
    "    .agg(pl.len(), pl.col(\"text\").mode().first())\n",
    "    .sort(\"len\", \"text\", descending=True)\n",
    ")\n",
    "summary.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table: Number of occurrences by reference. Use the mode of the text value.\n",
    "summary = df.group_by(\"text\").agg(pl.len()).sort(\"len\", \"text\", descending=True)\n",
    "summary.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxSGIV9bN-5l"
   },
   "source": [
    "## Adding Wikidata labels\n",
    "\n",
    "Because the text content of the same reference may take many forms, we may wish to fetch a more canonical label from Wikidata.\n",
    "\n",
    "The following `get_labels` function implements this using the Wikidata API.\n",
    "It accepts a Polars series as input and outputs a Polars series.\n",
    "It is later applied using the `map_batches` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get labels from Wikidata\n",
    "def get_labels(qids: pl.Series) -> pl.Series:\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    max_items = 50\n",
    "\n",
    "    # Split QIDs into chunks of max_items\n",
    "    qids_non_null = qids.drop_nulls()\n",
    "    qid_chunks = [\n",
    "        qids_non_null[i : i + max_items]\n",
    "        for i in range(0, len(qids_non_null), max_items)\n",
    "    ]\n",
    "\n",
    "    # Initialize an empty dictionary to store the results\n",
    "    entities_dict = {}\n",
    "\n",
    "    # Loop through each chunk of QIDs\n",
    "    for chunk in qid_chunks:\n",
    "        # Only request max_items at once\n",
    "        params = {\n",
    "            \"action\": \"wbgetentities\",\n",
    "            \"format\": \"json\",\n",
    "            \"props\": \"labels\",\n",
    "            \"languages\": \"de|en\",\n",
    "            \"ids\": \"|\".join(chunk),\n",
    "        }\n",
    "\n",
    "        # Make the API request\n",
    "        res = requests.get(url, params=params)\n",
    "        data = res.json()\n",
    "\n",
    "        # Update the dictionary with the new data\n",
    "        entities_dict.update(data[\"entities\"])\n",
    "\n",
    "    # Create a new Series with the original QIDs as the index\n",
    "    entities_list = []\n",
    "\n",
    "    # Populate the new series with the entities in the original order\n",
    "    for qid in qids:\n",
    "        item = entities_dict.get(qid, {})\n",
    "        # Get German label, fallback to English label\n",
    "        label = item.get(\"labels\", {}).get(\"de\", {}).get(\"value\")\n",
    "        if label is None:\n",
    "            label = item.get(\"labels\", {}).get(\"en\", {}).get(\"value\")\n",
    "\n",
    "        entities_list.append(label)\n",
    "\n",
    "    return pl.Series(entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    wikidata_label=pl.col(\"ref\")\n",
    "    .str.replace(\"http://www.wikidata.org/entity/\", \"\")  # Remove URL, Q-ID remains\n",
    "    .map_batches(function=get_labels)  # Apply get_labels\n",
    ")\n",
    "df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgU-PibuTcMh"
   },
   "source": [
    "## Plotting TEI elements and their pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Plotly histogram with persName and author sourceline\n",
    "import plotly.express as px\n",
    "\n",
    "pb_elements = pl.DataFrame(\n",
    "    etree_elements_to_dicts(dom.cssselect(\"head:not([type='sub'])\"))\n",
    ").filter(pl.col(\"text\") != \"ANHANG\")\n",
    "persons = pl.DataFrame(\n",
    "    etree_elements_to_dicts(\n",
    "        dom.cssselect(\"text persName, text quote, text sic, text rs, text placeName\")\n",
    "    )\n",
    ").with_columns(\n",
    "    page=pl.col(\"sourceline\").map_elements(\n",
    "        page_breaks.from_source_line, return_dtype=pl.Int64\n",
    "    )\n",
    ")\n",
    "\n",
    "tag_colours = {\n",
    "    \"persName\": px.colors.qualitative.Plotly[9],\n",
    "    \"quote\": px.colors.qualitative.Plotly[0],\n",
    "    \"sic\": px.colors.qualitative.Plotly[1],\n",
    "    \"rs\": px.colors.qualitative.Plotly[3],\n",
    "    \"placeName\": px.colors.qualitative.Plotly[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    persons,\n",
    "    x=\"page\",\n",
    "    color=\"name\",\n",
    "    nbins=100,\n",
    "    labels=dict(\n",
    "        name=\"Element\",\n",
    "        page=\"Page\",\n",
    "        count=\"Count\",\n",
    "    ),\n",
    "    title=\"Occurrences of various TEI tags\",\n",
    "    template=\"plotly_dark\",\n",
    "    color_discrete_map=tag_colours,\n",
    ")\n",
    "\n",
    "# Add vertical lines at page breaks\n",
    "for pb in pb_elements.to_dicts():\n",
    "    label = pb[\"text\"]\n",
    "    page = page_breaks.from_source_line(pb[\"sourceline\"])\n",
    "    fig.add_vline(x=page - 0.5, line_width=1, label=dict(text=label, yanchor=\"top\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1920\n",
    "height = 1080\n",
    "vh = height / 100\n",
    "\n",
    "# Set font size\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=3.2 * vh,\n",
    "    ),\n",
    "    paper_bgcolor=\"black\",\n",
    "    plot_bgcolor=\"black\",\n",
    ")\n",
    "\n",
    "fig.write_image(\"tag-occurrences.png\", width=width, height=height, scale=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
